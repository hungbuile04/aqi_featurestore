# ===== Import thÆ° viá»‡n =====
import pandas as pd
import numpy as np
import joblib
from feast import FeatureStore
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# ===== STEP 1: Káº¿t ná»‘i FEAST vÃ  láº¥y dá»¯ liá»‡u tá»« Offline Store =====
print("ğŸ”— Káº¿t ná»‘i Feature Store...")

# Káº¿t ná»‘i repo Feast (báº¡n thay path náº¿u cáº§n)
store = FeatureStore(repo_path=".")

# Chuáº©n bá»‹ entity dataframe chá»©a entity_id + event_timestamp
# (báº¡n cÃ³ thá»ƒ Ä‘á»c tá»« BigQuery náº¿u cáº§n)
entity_df = pd.DataFrame({
    "entity_id": ["21.0_105.75"] * 100,
    "event_timestamp": pd.date_range(start="2025-05-01", periods=100, freq="H")
})

# Truy váº¥n dá»¯ liá»‡u historical features tá»« Feast (láº¥y tá»« BigQuery)
print("ğŸ“¥ Truy váº¥n historical features tá»« offline store...")
training_df = store.get_historical_features(
    entity_df=entity_df,
    features=[
        "aqi_info_v1:hour",
        "aqi_info_v1:day",
        "aqi_info_v1:dayOfWeek",
        "aqi_info_v1:aqi"
    ]
).to_df()

print(f"âœ… Dá»¯ liá»‡u huáº¥n luyá»‡n: {training_df.shape}")

# ===== STEP 2: Tiá»n xá»­ lÃ½ features bá»• sung (tÃ­nh last_hour_aqi) =====

# Táº¡o cá»™t datetime chuáº©n hÃ³a (event_timestamp + hour)
training_df['datetime'] = pd.to_datetime(training_df['event_timestamp']) + pd.to_timedelta(training_df['hour'], unit='h')
training_df = training_df.sort_values('datetime')

# Táº¡o feature last_hour_aqi (shift 1 giá» trÆ°á»›c)
training_df['last_hour_aqi'] = training_df['aqi'].shift(1)

# Loáº¡i bá» cÃ¡c dÃ²ng cÃ³ NaN (do shift)
training_df = training_df.dropna()

# Chuáº©n bá»‹ dá»¯ liá»‡u input/output cho model
X = training_df[['hour', 'day', 'dayOfWeek', 'last_hour_aqi']]
y = training_df['aqi']

# ===== STEP 3: Huáº¥n luyá»‡n mÃ´ hÃ¬nh =====
print("ğŸ¤– Huáº¥n luyá»‡n mÃ´ hÃ¬nh...")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# ===== STEP 4: ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh =====
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("\nğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh:")
print(f"MAE  (Mean Absolute Error):      {mae:.2f}")
print(f"RMSE (Root Mean Squared Error): {rmse:.2f}")
print(f"RÂ²   (R-squared Score):          {r2:.3f}")

# ===== STEP 5: LÆ°u model =====
model_path = '/Users/buihung/VT/project1/model/aqi_model_hn.pkl'
joblib.dump(model, model_path)
print(f"âœ… MÃ´ hÃ¬nh Ä‘Ã£ lÆ°u táº¡i {model_path}")

# ===== STEP 6: MÃ´ phá»ng Serving Online =====
print("\nğŸ¯ Kiá»ƒm thá»­ dá»± Ä‘oÃ¡n online (Serving Demo)...")

# Giáº£ láº­p láº¥y feature online tá»« Feast
entity_id = "21.0_105.75"
online_features = store.get_online_features(
    features=[
        "aqi_info_v1:hour",
        "aqi_info_v1:day",
        "aqi_info_v1:dayOfWeek",
        "aqi_info_v1:aqi"
    ],
    entity_rows=[{"entity_id": entity_id}]
).to_dict()

# Chuáº©n bá»‹ dá»¯ liá»‡u phá»¥c vá»¥ serving inference
hour = online_features["hour"][0]
day = online_features["day"][0]
day_of_week = online_features["dayOfWeek"][0]
last_hour_aqi = online_features["aqi"][0]  # Giáº£ láº­p láº¥y tá»« online store

# Chuáº©n hÃ³a input model
input_data = pd.DataFrame([{
    "hour": hour,
    "day": day,
    "dayOfWeek": day_of_week,
    "last_hour_aqi": last_hour_aqi
}])

training_metadata = {
    "model_version": "v20240613",
    "feature_view_version": "aqi_info_v1",
    "offline_store": "BigQuery",
    "trained_at": "2024-06-13"
}

# GÃ³i model + metadata vÃ o 1 tuple
model_package = (model, training_metadata)
# Load láº¡i mÃ´ hÃ¬nh vÃ  dá»± Ä‘oÃ¡n
joblib.dump(model_package, model_path)
model_loaded, metadata_loaded = joblib.load(model_path)
pred = model_loaded.predict(input_data)
print(f"ğŸ¯ Dá»± Ä‘oÃ¡n AQI hiá»‡n táº¡i: {pred[0]:.2f}")


# Kiá»ƒm tra metadata
# Load láº¡i object tá»« file pkl
model_package = joblib.load("/Users/buihung/VT/project1/model/aqi_model_hn.pkl")

# TÃ¡ch ra model vÃ  metadata
loaded_model, loaded_metadata = model_package

# In metadata
print("ğŸ“Š Metadata kÃ¨m theo model:")
for k, v in loaded_metadata.items():
    print(f"{k}: {v}")